import numpy as np

# 0601 - 가중치에 대한 오류 편차를 줄여가는 과정

class Perceptron(object):
    # 4-1. 세팅 // eta : 학습수치, n_iter : for문으로 돌리는 횟수, random_state : 랜덤 시드 값
    def __init__(self, eta=0.01, n_iter=50, random_state=1):
        self.eta = eta
        self.n_iter = n_iter
        self.random_state = random_state

    def fit(self, X, y):
        # 4-2. 랜덤 값
        rgen = np.random.RandomState(self.random_state)
        # 4-3. 0.0 정도로, 0.01 표준편차(작을수록 중심값이 많음)로, X의 열+1만큼 가중치 랜덤 생성 
        # normal (평균값, 표준편차, 사이즈)
        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=(1 + X.shape[1]))   
        
        self.errors_ = []
        # 4-4. init에 설정한 횟수만큼 돌리기
        for _num in range(self.n_iter):
            errors = 0
            count = 0
            # zip(A,B) : A행, B행별로 for문 돌리겠다는 뜻
            # 4-5. 가중치 최신화
            for xi, target in zip(X, y):
                # 가산 증감수치 = 학습수치 * (결과값 - 예상값)
                update = self.eta * (target - self.predict(xi))              
                
                # 가산치 += 가산 증감수치
                self.w_[1:] += update * xi
                self.w_[0] += update
                # 결과값 != 예상값 이면, 에러에 추가
                errors += int(update != 0.0)
                count += 1
            self.errors_.append(errors)
        return self

    def net_input(self, X):
        # 4-7. 예상값을 2번째부터 X(조건)과 곱해서 추출
        return np.dot(X, self.w_[1:]) + self.w_[0]

    def predict(self, X):
        # 4-6. 예상값이 기준보다 크면 1
        return np.where(self.net_input(X) >= 0.0, 1, -1)


import pandas as pd

df = pd.read_csv('https://archive.ics.uci.edu/ml/'
        'machine-learning-databases/iris/iris.data', header=None)
df.tail()

#%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np

# setosa와 versicolor를 선택합니다 
# 1. 꽃 종류에 대한 값으로 결과치 추출
y = df.iloc[0:100, 4].values
y = np.where(y == 'Iris-setosa', -1, 1)

# 꽃받침 길이와 꽃잎 길이를 추출합니다
# 2. 조건 2개 100*2 행렬로 추출
X = df.iloc[0:100, [0, 2]].values

# 산점도를 그립니다
# 3. 그래프 그리기
plt.scatter(X[:50, 0], X[:50, 1],
            color='red', marker='o', label='setosa')
plt.scatter(X[50:100, 0], X[50:100, 1],
            color='blue', marker='x', label='versicolor')

plt.xlabel('sepal length [cm]')
plt.ylabel('petal length [cm]')
plt.legend(loc='upper left')

#plt.show()

# 4. 예측해보기
ppn = Perceptron(eta=0.1, n_iter=10)

ppn.fit(X, y)

# 5. x : 에러의 크기 y : 에러크기의 그래프로 표시
# plt.plot(range(1, len(ppn.errors_) + 1), ppn.errors_, marker='o')
# plt.xlabel('Epochs')
# plt.ylabel('Number of errors')

## 추가 함수 및 기능
# 0602 - 해당 구간에 대한 측정치를 통한 예상 분포도 출력

from matplotlib.colors import ListedColormap

def plot_decision_regions(X, y, classifier, resolution=0.001):

    # 마커와 컬러맵을 설정합니다
    markers = ('s', 'x', 'o', '^', 'v')
    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')
    cmap = ListedColormap(colors[:len(np.unique(y))])   
    
    # 결정 경계를 그립니다
    # X의 2가지 조건의 구간을 추출
    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    
    print(x1_min, x1_max , x2_min ,x2_max)
    
    # 305 * 235 행렬로 2개
    # xx1 : x1의 구간을 행렬로
    # xx2 : x2의 구간을 행렬로
    # meshgrid : 2/3차원 좌표값을 리턴
    # 1부터 5에 대한 모든 조합을 하기 위한 방법
    # 1, 2, 3 ...      1, 1, 1 ...
    # 1, 2, 3 ...      2, 2, 2 ...
    # 1, 2, 3 ...   x  3, 3, 3 ...
    # 1, 2, 3 ...      4, 4, 4 ...
    # 1, 2, 3 ...      5, 5, 5 ...
    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),
                           np.arange(x2_min, x2_max, resolution))
      
    # xx1.ravel() : 행별로 쪼개서 순서대로 넣음.-1 * 1 행렬로 재정의
    # .T : 전치행렬 
    # xx1과 xx2의 모든 조합 = 71675개의 경우 
    # Z = 71675 * 2 행렬에 대해, 측정값에 대한 71675 * 1 행렬로 리턴
    # Z = 305 * 235 행렬로
    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)
    Z = Z.reshape(xx1.shape)
    
    # countiurf : 등고선 그려주는 함수
    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap = cmap)

    # x/y 축 이름 넣어주기        
    plt.xlim(xx1.min(), xx1.max())    
    plt.ylim(xx2.min(), xx2.max())

    # 샘플의 산점도를 그립니다
    for idx, cl in enumerate(np.unique(y)):
        
        plt.scatter(x=X[y == cl, 0], 
                    y=X[y == cl, 1],
                    alpha=0.8, 
                    c=colors[idx],
                    marker=markers[idx], 
                    label=cl, 
                    edgecolor='black')
    

plot_decision_regions(X, y, classifier=ppn)
plt.xlabel('sepal length [cm]')
plt.ylabel('petal length [cm]')
plt.legend(loc='upper left')
plt.show()

 